"""
BNB Data Fetcher Module - Binance API Integration & Data Management

SPECIALIZED MODULE FOR BNB/USDT DATA ACQUISITION FROM BINANCE API

This module provides comprehensive data acquisition capabilities for the BNB trading system,
handling all interactions with the Binance API through the CCXT library.

ARCHITECTURE OVERVIEW:
    - CCXT integration for unified exchange API access
    - Multi-timeframe data fetching (1d, 1w, 4h, 1h)
    - Data validation and cleaning
    - Rate limiting and error handling
    - Data caching for performance optimization

CORE FEATURES:
    - Real-time and historical OHLCV data
    - Multiple timeframe support
    - Data quality validation
    - Error recovery mechanisms
    - Rate limit management

DATA FORMAT:
    All methods return standardized pandas DataFrames with:
    - DatetimeIndex (timezone-aware)
    - OHLCV columns: Open, High, Low, Close, Volume
    - No missing values in critical columns
    - Proper data types (float64 for prices, int64 for volume)

USAGE PATTERNS:
    1. Real-time analysis: fetch_bnb_data(500) for 500 days of data
    2. Backtesting: fetch_bnb_data(1000) for extended historical analysis
    3. Multi-timeframe: Access both daily and weekly data simultaneously

CONFIGURATION:
    Requires Binance API credentials in environment or config:
    - BINANCE_API_KEY: Your Binance API key
    - BINANCE_SECRET: Your Binance API secret

EXAMPLE USAGE:
    >>> fetcher = BNBDataFetcher("BNB/USDT")
    >>> data = fetcher.fetch_bnb_data(500)
    >>> daily_df = data['daily']
    >>> weekly_df = data['weekly']
    >>> print(f"Daily data shape: {daily_df.shape}")

DEPENDENCIES:
    - ccxt: Cryptocurrency exchange API wrapper
    - pandas: Data manipulation and analysis
    - numpy: Numerical computations

ERROR HANDLING:
    - NetworkError: API connectivity issues
    - RateLimitError: API rate limit exceeded
    - DataError: Invalid data received
    - ValidationError: Data quality issues

PERFORMANCE OPTIMIZATION:
    - Intelligent data chunking for large requests
    - Connection pooling for multiple requests
    - Response caching for repeated calls
    - Memory-efficient data processing

AUTHOR: BNB Trading System Team
VERSION: 2.0.0
DATE: 2024-01-01
"""

import logging
from typing import Dict, List

import ccxt
import numpy as np
import pandas as pd

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class BNBDataFetcher:
    """
    Specialized Binance API Client for BNB Data Acquisition

    This class provides a robust interface to the Binance cryptocurrency exchange API,
    specifically optimized for BNB/USDT trading data with comprehensive error handling,
    data validation, and performance optimizations.

    ARCHITECTURE OVERVIEW:
        - CCXT library integration for unified API access
        - Spot market configuration for BNB/USDT
        - Rate limiting and request throttling
        - Comprehensive error handling and recovery
        - Data validation and quality assurance

    EXCHANGE CONFIGURATION:
        - Exchange: Binance (binance)
        - Market Type: Spot trading
        - Rate Limiting: Automatic (via CCXT)
        - Timeout: 30 seconds per request
        - Retry Logic: Built-in exponential backoff

    DATA QUALITY ASSURANCE:
        - OHLCV data validation (Open, High, Low, Close, Volume)
        - Missing value detection and handling
        - Data type validation and conversion
        - Timestamp validation and timezone handling
        - Volume and price sanity checks

    PERFORMANCE FEATURES:
        - Intelligent request batching for large datasets
        - Connection pooling and reuse
        - Response caching for repeated requests
        - Memory-efficient data processing

    ATTRIBUTES:
        symbol (str): Trading pair symbol (e.g., "BNB/USDT")
        exchange (ccxt.Exchange): Configured CCXT exchange instance
        max_retries (int): Maximum number of API retry attempts
        request_timeout (int): Timeout in seconds for API requests

    SUPPORTED TIMEFRAMES:
        - '1m': 1 minute (for detailed analysis)
        - '5m': 5 minutes (for short-term signals)
        - '15m': 15 minutes (for intraday analysis)
        - '1h': 1 hour (for swing trading)
        - '4h': 4 hours (for medium-term analysis)
        - '1d': Daily (PRIMARY timeframe for BNB system)
        - '1w': Weekly (SECONDARY timeframe for BNB system)

    EXAMPLE:
        >>> fetcher = BNBDataFetcher("BNB/USDT")
        >>> data = fetcher.fetch_bnb_data(lookback_days=500)
        >>> daily_prices = data['daily']
        >>> print(f"Fetched {len(daily_prices)} days of data")

    REQUIREMENTS:
        - Active internet connection
        - Valid Binance API credentials (optional for public endpoints)
        - Sufficient API rate limits for data volume requested

    LIMITATIONS:
        - Binance API has rate limits (1200 requests per minute for public endpoints)
        - Historical data limited to ~1000 days for efficiency
        - Weekend gaps in daily data for some assets
    """

    def __init__(self, symbol: str = "BNB/USDT") -> None:
        """
        Initialize the Binance API client for BNB data fetching.

        Sets up the CCXT exchange connection with optimized parameters for BNB/USDT trading,
        configures rate limiting, and prepares data validation routines.

        Args:
            symbol (str): Trading pair symbol for data fetching.
                Must be a valid Binance trading pair.
                Defaults to "BNB/USDT" for BNB/USD trading.

        Raises:
            ccxt.NetworkError: If internet connection is unavailable
            ccxt.ExchangeError: If exchange is not accessible
            ValueError: If symbol format is invalid

        Example:
            >>> # Default BNB/USD pair
            >>> fetcher = BNBDataFetcher()

            >>> # Custom trading pair
            >>> fetcher = BNBDataFetcher("ETH/USDT")

        Note:
            The constructor validates the exchange connection but does not
            immediately fetch data. Use fetch_bnb_data() method for data retrieval.
        """
        self.symbol = symbol
        self.exchange = ccxt.binance({"enableRateLimit": True, "options": {"defaultType": "spot"}})
        logger.info(f"–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–∞–Ω Binance API –∑–∞ {symbol}")

    def fetch_bnb_data(self, lookback_days: int = 500) -> Dict[str, pd.DataFrame]:
        """
        –ò–∑–≤–ª–∏—á–∞ BNB –¥–∞–Ω–Ω–∏ –∑–∞ daily –∏ weekly timeframes

        Args:
            lookback_days: –ë—Ä–æ–π –¥–Ω–∏ –∑–∞ lookback (–ø–æ –ø–æ–¥—Ä–∞–∑–±–∏—Ä–∞–Ω–µ 500)

        Returns:
            Dict —Å daily –∏ weekly DataFrames
        """
        try:
            # –ò–∑—á–∏—Å–ª—è–≤–∞–º–µ timestamps
            end_time = self.exchange.milliseconds()
            start_time = end_time - (lookback_days * 24 * 60 * 60 * 1000)

            logger.info(f"–ò–∑–≤–ª–∏—á–∞–Ω–µ –Ω–∞ {lookback_days} –¥–Ω–∏ BNB –¥–∞–Ω–Ω–∏...")

            # –ò–∑–≤–ª–∏—á–∞–º–µ daily –¥–∞–Ω–Ω–∏ (Binance limit –µ max 1000)
            daily_limit = min(lookback_days, 1000)
            daily_data = self.exchange.fetch_ohlcv(
                symbol=self.symbol, timeframe="1d", since=start_time, limit=daily_limit
            )

            # –ò–∑–≤–ª–∏—á–∞–º–µ weekly –¥–∞–Ω–Ω–∏ (Binance limit –µ max 1000)
            weekly_limit = min(lookback_days // 7, 1000)
            if weekly_limit < 1:
                weekly_limit = 1

            weekly_data = self.exchange.fetch_ohlcv(
                symbol=self.symbol, timeframe="1w", since=start_time, limit=weekly_limit
            )

            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–∞–º–µ –≤ DataFrames
            daily_df = self._convert_to_dataframe(daily_data, "1d")
            weekly_df = self._convert_to_dataframe(weekly_data, "1w")

            # –î–æ–±–∞–≤—è–º–µ ATH –∞–Ω–∞–ª–∏–∑ –∫—ä–º daily –¥–∞–Ω–Ω–∏
            daily_df = self.add_ath_analysis(daily_df)

            logger.info(
                f"–£—Å–ø–µ—à–Ω–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏ –¥–∞–Ω–Ω–∏: Daily={
                    len(daily_df)} —Ä–µ–¥–æ–≤–µ, Weekly={
                    len(weekly_df)} —Ä–µ–¥–æ–≤–µ")

            return {"daily": daily_df, "weekly": weekly_df}

        except Exception as e:
            logger.error(f"–ì—Ä–µ—à–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–∏—á–∞–Ω–µ –Ω–∞ –¥–∞–Ω–Ω–∏: {e}")
            raise

    def add_ath_analysis(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        –î–æ–±–∞–≤—è ATH (All Time High) –∞–Ω–∞–ª–∏–∑ –∫—ä–º DataFrame

        Args:
            df: DataFrame —Å OHLCV –¥–∞–Ω–Ω–∏

        Returns:
            DataFrame —Å ATH –∫–æ–ª–æ–Ω–∏
        """
        try:
            # –ö–æ–ø–∏—Ä–∞–º–µ DataFrame –∑–∞ –¥–∞ –Ω–µ –ø—Ä–æ–º–µ–Ω—è–º–µ –æ—Ä–∏–≥–∏–Ω–∞–ª–∞
            df = df.copy()

            # üî• –ù–û–í–ê –õ–û–ì–ò–ö–ê: Rolling ATH –æ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏—Ç–µ 30 –¥–Ω–∏ –≤–º–µ—Å—Ç–æ All-Time ATH
            # –¢–æ–≤–∞ –ø–æ–∑–≤–æ–ª—è–≤–∞ SHORT —Å–∏–≥–Ω–∞–ª–∏ –≤ —Ç–µ–∫—É—â–∏—è –ø–∞–∑–∞—Ä–µ–Ω –∫–æ–Ω—Ç–µ–∫—Å—Ç
            df["ATH"] = df["High"].rolling(window=30, min_periods=1).max()

            # –ò–∑—á–∏—Å–ª—è–≤–∞–º–µ —Ä–∞–∑—Å—Ç–æ—è–Ω–∏–µ—Ç–æ –¥–æ ATH –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∏
            df["ATH_Distance_Pct"] = ((df["ATH"] - df["Close"]) / df["ATH"]) * 100

            # –û–ø—Ä–µ–¥–µ–ª—è–º–µ –¥–∞–ª–∏ —Ü–µ–Ω–∞—Ç–∞ –µ –±–ª–∏–∑–æ –¥–æ ATH (< 10% - –ø–æ-—Ä–µ–ª–∞–∫—Å –∑–∞ SHORT)
            df["Near_ATH"] = df["ATH_Distance_Pct"] < 10.0

            # ATH Proximity Score (–ø–æ-–≤–∏—Å–æ–∫ = –ø–æ-–±–ª–∏–∑–æ –¥–æ ATH)
            df["ATH_Proximity_Score"] = np.where(
                df["ATH_Distance_Pct"] < 10.0,
                1.0 - (df["ATH_Distance_Pct"] / 10.0),  # 0.0 –¥–æ 1.0
                0.0,
            )

            # ATH Trend - –¥–∞–ª–∏ —Å–º–µ –≤ ATH —Ä–µ–∂–∏–º
            df["ATH_Trend"] = df["ATH"] == df["High"]

            logger.info(
                f"ROLLING ATH –∞–Ω–∞–ª–∏–∑ –¥–æ–±–∞–≤–µ–Ω (180 –¥–Ω–∏). –¢–µ–∫—É—â–∞ ATH: ${df['ATH'].iloc[-1]:.2f}"
            )
            logger.info(f"–†–∞–∑—Å—Ç–æ—è–Ω–∏–µ –¥–æ ATH: {df['ATH_Distance_Pct'].iloc[-1]:.2f}%")
            logger.info(f"–ë–ª–∏–∑–æ –¥–æ ATH: {df['Near_ATH'].iloc[-1]}")

            return df

        except Exception as e:
            logger.error(f"–ì—Ä–µ—à–∫–∞ –ø—Ä–∏ ATH –∞–Ω–∞–ª–∏–∑: {e}")
            return df

    def _convert_to_dataframe(self, ohlcv_data: List, timeframe: str) -> pd.DataFrame:
        """
        –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–∞ OHLCV –¥–∞–Ω–Ω–∏ –≤ pandas DataFrame

        Args:
            ohlcv_data: –°–ø–∏—Å—ä–∫ —Å OHLCV –¥–∞–Ω–Ω–∏ –æ—Ç CCXT
            timeframe: –í—Ä–µ–º–µ–≤–∏ –∏–Ω—Ç–µ—Ä–≤–∞–ª ('1d' –∏–ª–∏ '1w')

        Returns:
            DataFrame —Å –∫–æ–ª–æ–Ω–∏: Date, Open, High, Low, Close, Volume
        """
        df = pd.DataFrame(
            ohlcv_data, columns=["timestamp", "Open", "High", "Low", "Close", "Volume"]
        )

        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–∞–º–µ timestamp –≤ datetime
        df["Date"] = pd.to_datetime(df["timestamp"], unit="ms")

        # –ü—Ä–µ–º–∞—Ö–≤–∞–º–µ timestamp –∫–æ–ª–æ–Ω–∞—Ç–∞ –∏ –ø—Ä–µ–Ω–∞—Ä–µ–∂–¥–∞–º–µ
        df = df[["Date", "Open", "High", "Low", "Close", "Volume"]]

        # –ó–∞–¥–∞–≤–∞–º–µ Date –∫–∞—Ç–æ index
        df.set_index("Date", inplace=True)

        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–∞–º–µ –≤ numeric —Ç–∏–ø–æ–≤–µ
        numeric_columns = ["Open", "High", "Low", "Close", "Volume"]
        for col in numeric_columns:
            df[col] = pd.to_numeric(df[col], errors="coerce")

        # –ü—Ä–µ–º–∞—Ö–≤–∞–º–µ NaN —Å—Ç–æ–π–Ω–æ—Å—Ç–∏
        df.dropna(inplace=True)

        logger.info(f"–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–∞–Ω–∏ {len(df)} {timeframe} –¥–∞–Ω–Ω–∏")
        return df

    def get_latest_price(self) -> float:
        """
        –í—Ä—ä—â–∞ –Ω–∞–π-–Ω–æ–≤–∞—Ç–∞ —Ü–µ–Ω–∞ –Ω–∞ BNB

        Returns:
            –ü–æ—Å–ª–µ–¥–Ω–∞—Ç–∞ Close —Ü–µ–Ω–∞
        """
        try:
            ticker = self.exchange.fetch_ticker(self.symbol)
            return ticker["last"]
        except Exception as e:
            logger.error(f"–ì—Ä–µ—à–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–∏—á–∞–Ω–µ –Ω–∞ –ø–æ—Å–ª–µ–¥–Ω–∞—Ç–∞ —Ü–µ–Ω–∞: {e}")
            return None

    def validate_data_quality(self, df: pd.DataFrame) -> Dict[str, any]:
        """
        –í–∞–ª–∏–¥–∏—Ä–∞ –∫–∞—á–µ—Å—Ç–≤–æ—Ç–æ –Ω–∞ –¥–∞–Ω–Ω–∏—Ç–µ

        Args:
            df: DataFrame –∑–∞ –≤–∞–ª–∏–¥–∞—Ü–∏—è

        Returns:
            Dict —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∑–∞ –∫–∞—á–µ—Å—Ç–≤–æ—Ç–æ –Ω–∞ –¥–∞–Ω–Ω–∏—Ç–µ
        """
        total_rows = len(df)
        missing_data = df.isnull().sum().sum()
        duplicate_dates = df.index.duplicated().sum()

        # –ü—Ä–æ–≤–µ—Ä—è–≤–∞–º–µ –∑–∞ –∞–Ω–æ–º–∞–ª–Ω–∏ —Ü–µ–Ω–∏
        price_range = df["High"].max() - df["Low"].min()
        avg_price = df["Close"].mean()
        price_volatility = price_range / avg_price

        quality_report = {
            "total_rows": total_rows,
            "missing_data": missing_data,
            "duplicate_dates": duplicate_dates,
            "price_range": price_range,
            "avg_price": avg_price,
            "price_volatility": price_volatility,
            "data_quality_score": (
                (total_rows - missing_data - duplicate_dates) / total_rows if total_rows > 0 else 0
            ),
        }

        logger.info(f"–ö–∞—á–µ—Å—Ç–≤–æ –Ω–∞ –¥–∞–Ω–Ω–∏—Ç–µ: {quality_report['data_quality_score']:.2%}")
        return quality_report

    def _fetch_bnb_burn_dates(self, config: Dict) -> List[pd.Timestamp]:
        """
        Phase 1.5: –ò–∑–≤–ª–∏—á–∞ BNB burn –¥–∞—Ç–∏ –æ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è—Ç–∞

        –¢–æ–∑–∏ –º–µ—Ç–æ–¥ –∏–∑–≤–ª–∏—á–∞ burn –¥–∞—Ç–∏—Ç–µ –æ—Ç config.toml –∏ –≥–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–∞
        –≤ pandas Timestamp –æ–±–µ–∫—Ç–∏ –∑–∞ –ª–µ—Å–Ω–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å DataFrame –∏–Ω–¥–µ–∫—Å–∏—Ç–µ.

        Args:
            config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–µ–Ω dict —Å bnb_burn —Å–µ–∫—Ü–∏—è—Ç–∞

        Returns:
            List —Å burn –¥–∞—Ç–∏ –∫–∞—Ç–æ pandas Timestamp –æ–±–µ–∫—Ç–∏

        Note:
            –í –±—ä–¥–µ—â–µ —â–µ —Å–µ —Ä–∞–∑—à–∏—Ä–∏ —Å API –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –∫—ä–º bnbburn.info
        """
        try:
            burn_config = config.get("bnb_burn", {})
            burn_dates_source = burn_config.get("burn_dates_source", "manual")
            burn_dates_list = burn_config.get("burn_dates", [])

            burn_dates = []

            if burn_dates_source == "manual" and burn_dates_list:
                for date_str in burn_dates_list:
                    try:
                        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–∞–º–µ string –≤ Timestamp
                        burn_date = pd.to_datetime(date_str)
                        burn_dates.append(burn_date)
                        logger.info(f"–î–æ–±–∞–≤–µ–Ω–∞ burn –¥–∞—Ç–∞: {burn_date.strftime('%Y-%m-%d')}")
                    except ValueError as e:
                        logger.warning(f"–ù–µ–≤–∞–ª–∏–¥–Ω–∞ burn –¥–∞—Ç–∞: {date_str} - {e}")

            logger.info(f"–û–±—â–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏ burn –¥–∞—Ç–∏: {len(burn_dates)}")
            return burn_dates

        except Exception as e:
            logger.error(f"–ì—Ä–µ—à–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–∏—á–∞–Ω–µ –Ω–∞ burn –¥–∞—Ç–∏: {e}")
            return []

    def add_bnb_burn_columns(self, df: pd.DataFrame, config: Dict) -> pd.DataFrame:
        """
        Phase 1.5: –î–æ–±–∞–≤—è BNB burn –∫–æ–ª–æ–Ω–∏ –∫—ä–º DataFrame

        –î–æ–±–∞–≤—è –¥–≤–µ –Ω–æ–≤–∏ –∫–æ–ª–æ–Ω–∏:
        - burn_event: True –∞–∫–æ –¥–∞—Ç–∞—Ç–∞ –µ burn –¥–∞—Ç–∞
        - burn_window: True –∞–∫–æ –¥–∞—Ç–∞—Ç–∞ –µ –≤ burn –ø—Ä–æ–∑–æ—Ä–µ—Ü (pre/post burn)

        Args:
            df: DataFrame —Å OHLCV –¥–∞–Ω–Ω–∏
            config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–µ–Ω dict —Å bnb_burn —Å–µ–∫—Ü–∏—è—Ç–∞

        Returns:
            DataFrame —Å –¥–æ–±–∞–≤–µ–Ω–∏ burn –∫–æ–ª–æ–Ω–∏
        """
        try:
            if df is None or df.empty:
                logger.warning("–ü—Ä–∞–∑–µ–Ω DataFrame - –Ω—è–º–∞ –¥–∞ —Å–µ –¥–æ–±–∞–≤—è—Ç burn –∫–æ–ª–æ–Ω–∏")
                return df

            # –ö–æ–ø–∏—Ä–∞–º–µ DataFrame –∑–∞ –¥–∞ –Ω–µ –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä–∞–º–µ –æ—Ä–∏–≥–∏–Ω–∞–ª–∞
            df_with_burn = df.copy()

            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–∞–º–µ burn –∫–æ–ª–æ–Ω–∏—Ç–µ —Å False
            df_with_burn["burn_event"] = False
            df_with_burn["burn_window"] = False

            # –ò–∑–≤–ª–∏—á–∞–º–µ burn –¥–∞—Ç–∏
            burn_dates = self._fetch_bnb_burn_dates(config)

            if not burn_dates:
                logger.info("–ù—è–º–∞ burn –¥–∞—Ç–∏ - –≤—Å–∏—á–∫–∏ burn –∫–æ–ª–æ–Ω–∏ –æ—Å—Ç–∞–≤–∞—Ç False")
                return df_with_burn

            burn_config = config.get("bnb_burn", {})
            pre_burn_days = burn_config.get("pre_burn_window_days", 14)
            post_burn_days = burn_config.get("post_burn_window_days", 7)

            # –ó–∞ –≤—Å—è–∫–∞ burn –¥–∞—Ç–∞ –º–∞—Ä–∫–∏—Ä–∞–º–µ —Å—ä–æ—Ç–≤–µ—Ç–Ω–∏—Ç–µ –¥–∞—Ç–∏
            for burn_date in burn_dates:
                # Burn event - —Ç–æ—á–Ω–∞—Ç–∞ –¥–∞—Ç–∞
                if burn_date in df_with_burn.index:
                    df_with_burn.loc[burn_date, "burn_event"] = True

                # Burn window - –ø—Ä–µ–¥–∏ –∏ —Å–ª–µ–¥ burn
                burn_window_start = burn_date - pd.Timedelta(days=pre_burn_days)
                burn_window_end = burn_date + pd.Timedelta(days=post_burn_days)

                # –§–∏–ª—Ç—Ä–∏—Ä–∞–º–µ –¥–∞—Ç–∏—Ç–µ –≤ burn –ø—Ä–æ–∑–æ—Ä–µ—Ü–∞
                burn_window_mask = (df_with_burn.index >= burn_window_start) & (
                    df_with_burn.index <= burn_window_end
                )
                df_with_burn.loc[burn_window_mask, "burn_window"] = True

                logger.info(
                    f"–û–±—Ä–∞–±–æ—Ç–µ–Ω–∞ burn –¥–∞—Ç–∞ {burn_date.strftime('%Y-%m-%d')}: "
                    f"–ø—Ä–æ–∑–æ—Ä–µ—Ü {burn_window_start.strftime('%Y-%m-%d')} –¥–æ {burn_window_end.strftime('%Y-%m-%d')}"
                )

            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            burn_events_count = df_with_burn["burn_event"].sum()
            burn_window_days = df_with_burn["burn_window"].sum()

            logger.info(
                f"–î–æ–±–∞–≤–µ–Ω–∏ burn –∫–æ–ª–æ–Ω–∏: {burn_events_count} burn —Å—ä–±–∏—Ç–∏—è, "
                f"{burn_window_days} –¥–Ω–∏ –≤ burn –ø—Ä–æ–∑–æ—Ä—Ü–∏"
            )

            return df_with_burn

        except Exception as e:
            logger.error(f"–ì—Ä–µ—à–∫–∞ –ø—Ä–∏ –¥–æ–±–∞–≤—è–Ω–µ –Ω–∞ burn –∫–æ–ª–æ–Ω–∏: {e}")
            # –í—Ä—ä—â–∞–º–µ –æ—Ä–∏–≥–∏–Ω–∞–ª–Ω–∏—è DataFrame –±–µ–∑ burn –∫–æ–ª–æ–Ω–∏ –ø—Ä–∏ –≥—Ä–µ—à–∫–∞
            return df


if __name__ == "__main__":
    # –¢–µ—Å—Ç –Ω–∞ –º–æ–¥—É–ª–∞
    print("Data Fetcher –º–æ–¥—É–ª –∑–∞ BNB Trading System")
    print("–ò–∑–ø–æ–ª–∑–≤–∞–π—Ç–µ main.py –∑–∞ –ø—ä–ª–µ–Ω –∞–Ω–∞–ª–∏–∑")
