"""Data validation functions for BNB Trading System."""

import logging
from typing import Any

import numpy as np
import pandas as pd

from bnb_trading.core.exceptions import DataError

logger = logging.getLogger(__name__)


def add_ath_analysis(df: pd.DataFrame) -> pd.DataFrame:
    """
    –î–æ–±–∞–≤—è ATH (All Time High) –∞–Ω–∞–ª–∏–∑ –∫—ä–º DataFrame

    Args:
        df: DataFrame —Å OHLCV –¥–∞–Ω–Ω–∏

    Returns:
        DataFrame —Å ATH –∫–æ–ª–æ–Ω–∏
    """
    try:
        # –ö–æ–ø–∏—Ä–∞–º–µ DataFrame –∑–∞ –¥–∞ –Ω–µ –ø—Ä–æ–º–µ–Ω—è–º–µ –æ—Ä–∏–≥–∏–Ω–∞–ª–∞
        df = df.copy()

        # üî• –ù–û–í–ê –õ–û–ì–ò–ö–ê: Rolling ATH –æ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏—Ç–µ 180 –¥–Ω–∏ –∑–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∞ —Ç–æ—á–Ω–æ—Å—Ç
        # –¢–æ–≤–∞ –ø–æ–∑–≤–æ–ª—è–≤–∞ SHORT —Å–∏–≥–Ω–∞–ª–∏ –≤ —Ç–µ–∫—É—â–∏—è –ø–∞–∑–∞—Ä–µ–Ω –∫–æ–Ω—Ç–µ–∫—Å—Ç
        df["ATH"] = df["High"].rolling(window=180, min_periods=30).max()

        # –ò–∑—á–∏—Å–ª—è–≤–∞–º–µ —Ä–∞–∑—Å—Ç–æ—è–Ω–∏–µ—Ç–æ –¥–æ ATH –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∏
        df["ATH_Distance_Pct"] = ((df["ATH"] - df["Close"]) / df["ATH"]) * 100

        # –û–ø—Ä–µ–¥–µ–ª—è–º–µ –¥–∞–ª–∏ —Ü–µ–Ω–∞—Ç–∞ –µ –±–ª–∏–∑–æ –¥–æ ATH (< 10% - –ø–æ-—Ä–µ–ª–∞–∫—Å –∑–∞ SHORT)
        df["Near_ATH"] = df["ATH_Distance_Pct"] < 10.0

        # ATH Proximity Score (–ø–æ-–≤–∏—Å–æ–∫ = –ø–æ-–±–ª–∏–∑–æ –¥–æ ATH)
        df["ATH_Proximity_Score"] = np.where(
            df["ATH_Distance_Pct"] < 10.0,
            1.0 - (df["ATH_Distance_Pct"] / 10.0),  # 0.0 –¥–æ 1.0
            0.0,
        )

        # ATH Trend - –¥–∞–ª–∏ —Å–º–µ –≤ ATH —Ä–µ–∂–∏–º
        df["ATH_Trend"] = df["ATH"] == df["High"]

        logger.info(
            f"ROLLING ATH –∞–Ω–∞–ª–∏–∑ –¥–æ–±–∞–≤–µ–Ω (180 –¥–Ω–∏). –¢–µ–∫—É—â–∞ ATH: ${df['ATH'].iloc[-1]:.2f}"
        )
        logger.info(f"–†–∞–∑—Å—Ç–æ—è–Ω–∏–µ –¥–æ ATH: {df['ATH_Distance_Pct'].iloc[-1]:.2f}%")
        logger.info(f"–ë–ª–∏–∑–æ –¥–æ ATH: {df['Near_ATH'].iloc[-1]}")

        return df

    except Exception as e:
        logger.exception(f"–ì—Ä–µ—à–∫–∞ –ø—Ä–∏ ATH –∞–Ω–∞–ª–∏–∑: {e}")
        return df


def add_bnb_burn_columns(df: pd.DataFrame, config: dict) -> pd.DataFrame:
    """
    Phase 1.5: –î–æ–±–∞–≤—è BNB burn –∫–æ–ª–æ–Ω–∏ –∫—ä–º DataFrame

    –î–æ–±–∞–≤—è –¥–≤–µ –Ω–æ–≤–∏ –∫–æ–ª–æ–Ω–∏:
    - burn_event: True –∞–∫–æ –¥–∞—Ç–∞—Ç–∞ –µ burn –¥–∞—Ç–∞
    - burn_window: True –∞–∫–æ –¥–∞—Ç–∞—Ç–∞ –µ –≤ burn –ø—Ä–æ–∑–æ—Ä–µ—Ü (pre/post burn)

    Args:
        df: DataFrame —Å OHLCV –¥–∞–Ω–Ω–∏
        config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–µ–Ω dict —Å bnb_burn —Å–µ–∫—Ü–∏—è—Ç–∞

    Returns:
        DataFrame —Å –¥–æ–±–∞–≤–µ–Ω–∏ burn –∫–æ–ª–æ–Ω–∏
    """
    try:
        if df is None or df.empty:
            logger.warning("–ü—Ä–∞–∑–µ–Ω DataFrame - –Ω—è–º–∞ –¥–∞ —Å–µ –¥–æ–±–∞–≤—è—Ç burn –∫–æ–ª–æ–Ω–∏")
            return df

        # –ö–æ–ø–∏—Ä–∞–º–µ DataFrame –∑–∞ –¥–∞ –Ω–µ –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä–∞–º–µ –æ—Ä–∏–≥–∏–Ω–∞–ª–∞
        df_with_burn = df.copy()

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–∞–º–µ burn –∫–æ–ª–æ–Ω–∏—Ç–µ —Å False
        df_with_burn["burn_event"] = False
        df_with_burn["burn_window"] = False

        # –ò–∑–≤–ª–∏—á–∞–º–µ burn –¥–∞—Ç–∏
        burn_dates = _fetch_bnb_burn_dates(config)

        if not burn_dates:
            logger.info("–ù—è–º–∞ burn –¥–∞—Ç–∏ - –≤—Å–∏—á–∫–∏ burn –∫–æ–ª–æ–Ω–∏ –æ—Å—Ç–∞–≤–∞—Ç False")
            return df_with_burn

        burn_config = config.get("bnb_burn", {})
        pre_burn_days = burn_config.get("pre_burn_window_days", 14)
        post_burn_days = burn_config.get("post_burn_window_days", 7)

        # –ó–∞ –≤—Å—è–∫–∞ burn –¥–∞—Ç–∞ –º–∞—Ä–∫–∏—Ä–∞–º–µ —Å—ä–æ—Ç–≤–µ—Ç–Ω–∏—Ç–µ –¥–∞—Ç–∏
        for burn_date in burn_dates:
            # Burn event - —Ç–æ—á–Ω–∞—Ç–∞ –¥–∞—Ç–∞
            if burn_date in df_with_burn.index:
                df_with_burn.loc[burn_date, "burn_event"] = True

            # Burn window - –ø—Ä–µ–¥–∏ –∏ —Å–ª–µ–¥ burn
            burn_window_start = burn_date - pd.Timedelta(days=pre_burn_days)
            burn_window_end = burn_date + pd.Timedelta(days=post_burn_days)

            # –§–∏–ª—Ç—Ä–∏—Ä–∞–º–µ –¥–∞—Ç–∏—Ç–µ –≤ burn –ø—Ä–æ–∑–æ—Ä–µ—Ü–∞
            burn_window_mask = (df_with_burn.index >= burn_window_start) & (
                df_with_burn.index <= burn_window_end
            )
            df_with_burn.loc[burn_window_mask, "burn_window"] = True

            logger.info(
                f"–û–±—Ä–∞–±–æ—Ç–µ–Ω–∞ burn –¥–∞—Ç–∞ {burn_date.strftime('%Y-%m-%d')}: "
                f"–ø—Ä–æ–∑–æ—Ä–µ—Ü {burn_window_start.strftime('%Y-%m-%d')} –¥–æ {burn_window_end.strftime('%Y-%m-%d')}"
            )

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        burn_events_count = df_with_burn["burn_event"].sum()
        burn_window_days = df_with_burn["burn_window"].sum()

        logger.info(
            f"–î–æ–±–∞–≤–µ–Ω–∏ burn –∫–æ–ª–æ–Ω–∏: {burn_events_count} burn —Å—ä–±–∏—Ç–∏—è, "
            f"{burn_window_days} –¥–Ω–∏ –≤ burn –ø—Ä–æ–∑–æ—Ä—Ü–∏"
        )

        return df_with_burn

    except Exception as e:
        logger.exception(f"–ì—Ä–µ—à–∫–∞ –ø—Ä–∏ –¥–æ–±–∞–≤—è–Ω–µ –Ω–∞ burn –∫–æ–ª–æ–Ω–∏: {e}")
        # –í—Ä—ä—â–∞–º–µ –æ—Ä–∏–≥–∏–Ω–∞–ª–Ω–∏—è DataFrame –±–µ–∑ burn –∫–æ–ª–æ–Ω–∏ –ø—Ä–∏ –≥—Ä–µ—à–∫–∞
        return df


def validate_data_quality(df: pd.DataFrame) -> dict[str, Any]:
    """
    –í–∞–ª–∏–¥–∏—Ä–∞ –∫–∞—á–µ—Å—Ç–≤–æ—Ç–æ –Ω–∞ –¥–∞–Ω–Ω–∏—Ç–µ

    Args:
        df: DataFrame –∑–∞ –≤–∞–ª–∏–¥–∞—Ü–∏—è

    Returns:
        Dict —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∑–∞ –∫–∞—á–µ—Å—Ç–≤–æ—Ç–æ –Ω–∞ –¥–∞–Ω–Ω–∏—Ç–µ
    """
    if df is None or df.empty:
        raise DataError("Empty or None DataFrame provided for validation")

    total_rows = len(df)
    missing_data = df.isnull().sum().sum()
    duplicate_dates = df.index.duplicated().sum()

    # –ü—Ä–æ–≤–µ—Ä—è–≤–∞–º–µ –∑–∞ –∞–Ω–æ–º–∞–ª–Ω–∏ —Ü–µ–Ω–∏
    price_range = df["High"].max() - df["Low"].min()
    avg_price = df["Close"].mean()
    price_volatility = price_range / avg_price

    quality_report = {
        "total_rows": total_rows,
        "missing_data": missing_data,
        "duplicate_dates": duplicate_dates,
        "price_range": price_range,
        "avg_price": avg_price,
        "price_volatility": price_volatility,
        "data_quality_score": (
            (total_rows - missing_data - duplicate_dates) / total_rows
            if total_rows > 0
            else 0
        ),
    }

    logger.info(f"–ö–∞—á–µ—Å—Ç–≤–æ –Ω–∞ –¥–∞–Ω–Ω–∏—Ç–µ: {quality_report['data_quality_score']:.2%}")
    return quality_report


def _fetch_bnb_burn_dates(config: dict) -> list[pd.Timestamp]:
    """
    Phase 1.5: –ò–∑–≤–ª–∏—á–∞ BNB burn –¥–∞—Ç–∏ –æ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è—Ç–∞

    –¢–æ–∑–∏ –º–µ—Ç–æ–¥ –∏–∑–≤–ª–∏—á–∞ burn –¥–∞—Ç–∏—Ç–µ –æ—Ç config.toml –∏ –≥–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–∞
    –≤ pandas Timestamp –æ–±–µ–∫—Ç–∏ –∑–∞ –ª–µ—Å–Ω–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å DataFrame –∏–Ω–¥–µ–∫—Å–∏—Ç–µ.

    Args:
        config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–µ–Ω dict —Å bnb_burn —Å–µ–∫—Ü–∏—è—Ç–∞

    Returns:
        List —Å burn –¥–∞—Ç–∏ –∫–∞—Ç–æ pandas Timestamp –æ–±–µ–∫—Ç–∏

    Note:
        –í –±—ä–¥–µ—â–µ —â–µ —Å–µ —Ä–∞–∑—à–∏—Ä–∏ —Å API –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –∫—ä–º bnbburn.info
    """
    try:
        burn_config = config.get("bnb_burn", {})
        burn_dates_source = burn_config.get("burn_dates_source", "manual")
        burn_dates_list = burn_config.get("burn_dates", [])

        burn_dates = []

        if burn_dates_source == "manual" and burn_dates_list:
            for date_str in burn_dates_list:
                try:
                    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–∞–º–µ string –≤ Timestamp
                    burn_date = pd.to_datetime(date_str)
                    burn_dates.append(burn_date)
                    logger.info(f"–î–æ–±–∞–≤–µ–Ω–∞ burn –¥–∞—Ç–∞: {burn_date.strftime('%Y-%m-%d')}")
                except ValueError as e:
                    logger.warning(f"–ù–µ–≤–∞–ª–∏–¥–Ω–∞ burn –¥–∞—Ç–∞: {date_str} - {e}")

        logger.info(f"–û–±—â–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏ burn –¥–∞—Ç–∏: {len(burn_dates)}")
        return burn_dates

    except Exception as e:
        logger.exception(f"–ì—Ä–µ—à–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–∏—á–∞–Ω–µ –Ω–∞ burn –¥–∞—Ç–∏: {e}")
        return []
